{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "from sklearn.externals import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainList = []\n",
    "trainLabels = []\n",
    "testList = []\n",
    "testLabels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['drawings', 'engraving', 'iconography', 'painting', 'sculpture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'drawings': [1,0,0,0,0],\n",
    "          'engraving': [0,1,0,0,0],\n",
    "          'iconography': [0,0,1,0,0],\n",
    "          'painting': [0,0,0,1,0],\n",
    "          'sculpture': [0,0,0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawings: \n",
      "1107\n",
      "engraving: \n",
      "757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vesko\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6029312 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\vesko\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1311848 bytes but only got 785. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\vesko\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iconography: \n",
      "2077\n",
      "painting: \n",
      "2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vesko\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\Image.py:969: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sculpture: \n",
      "1738\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    count = 0\n",
    "    for filename in glob.glob('art-images/dataset/dataset_updated/training_set/' + folder +'/*'):\n",
    "        try:\n",
    "            count = count + 1\n",
    "            im = Image.open(filename).convert('RGB')\n",
    "            im = im.resize((64,64))\n",
    "            imArr = np.array(im)\n",
    "            trainList.append(imArr)\n",
    "        \n",
    "            trainLabels.append(labels[folder])\n",
    "        except OSError as e:\n",
    "            pass\n",
    "    print(folder + \": \")\n",
    "    print(count)\n",
    "    #print(np.array(trainList).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawings: \n",
      "122\n",
      "engraving: \n",
      "84\n",
      "iconography: \n",
      "231\n",
      "painting: \n",
      "228\n",
      "sculpture: \n",
      "191\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    count = 0\n",
    "    for filename in glob.glob('art-images/dataset/dataset_updated/validation_set/' + folder +'/*'):\n",
    "        try:\n",
    "            count = count+1\n",
    "            im = Image.open(filename).convert('RGB')\n",
    "            im = im.resize((64,64))\n",
    "            imArr = np.array(im)\n",
    "            testList.append(imArr)\n",
    "            testLabels.append(labels[folder])\n",
    "        except OSError as e:\n",
    "            pass\n",
    "    print(folder + \": \")\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(testList).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(testLabels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7721, 64, 64, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainList).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7721, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainLabels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', padding=\"same\",\n",
    "                 input_shape = (64, 64, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7721, 64, 64, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainList).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainArr = np.array(trainList)\n",
    "trainArr = trainArr/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testArr = np.array(testList)\n",
    "testArr = testArr / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"best_weights_of_old.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "230/230 [==============================] - 1911s 8s/step - loss: 1.4326 - acc: 0.3535\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 365s 2s/step - loss: 1.0313 - acc: 0.6003\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 479s 2s/step - loss: 0.9015 - acc: 0.6610\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 478s 2s/step - loss: 0.8931 - acc: 0.6663\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 283s 1s/step - loss: 0.8152 - acc: 0.6996\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 480s 2s/step - loss: 0.7635 - acc: 0.7149\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 479s 2s/step - loss: 0.7428 - acc: 0.7347\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 415s 2s/step - loss: 0.6998 - acc: 0.7633\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 391s 2s/step - loss: 0.6544 - acc: 0.7654\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 233s 1s/step - loss: 0.6470 - acc: 0.7663\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vesko\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\callbacks.py:434: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 229s 994ms/step - loss: 0.6049 - acc: 0.7838\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 226s 983ms/step - loss: 0.6476 - acc: 0.7753\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 226s 983ms/step - loss: 0.5889 - acc: 0.7923\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 230s 1000ms/step - loss: 0.5966 - acc: 0.7932\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 227s 986ms/step - loss: 0.5548 - acc: 0.8039\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.5191 - acc: 0.8147\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 226s 982ms/step - loss: 0.5265 - acc: 0.8099\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.5032 - acc: 0.8201\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 225s 978ms/step - loss: 0.5101 - acc: 0.8168\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 234s 1s/step - loss: 0.5087 - acc: 0.8095\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 227s 988ms/step - loss: 0.4780 - acc: 0.8302\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 228s 991ms/step - loss: 0.4709 - acc: 0.8280\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 227s 987ms/step - loss: 0.5032 - acc: 0.8196\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 227s 986ms/step - loss: 0.4770 - acc: 0.8289\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 227s 987ms/step - loss: 0.4536 - acc: 0.8348\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 225s 980ms/step - loss: 0.4383 - acc: 0.8425\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.4562 - acc: 0.8310\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 225s 979ms/step - loss: 0.4570 - acc: 0.8338\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.4294 - acc: 0.8421\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 228s 990ms/step - loss: 0.4127 - acc: 0.8528\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.4190 - acc: 0.8497\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 226s 984ms/step - loss: 0.4290 - acc: 0.8441\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 227s 987ms/step - loss: 0.4336 - acc: 0.8492\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.3950 - acc: 0.8563\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 225s 980ms/step - loss: 0.3920 - acc: 0.8582\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 226s 983ms/step - loss: 0.4379 - acc: 0.8362\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 226s 983ms/step - loss: 0.3759 - acc: 0.8587\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.3966 - acc: 0.8481\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 227s 986ms/step - loss: 0.3677 - acc: 0.8633\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 226s 981ms/step - loss: 0.3872 - acc: 0.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eca0cfcf28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(trainArr, np.array(trainLabels), batch_size=16),steps_per_epoch=230, epochs=40, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"best_weights_of_old.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'art-images\\\\dataset\\\\dataset_updated\\\\validation_set\\\\painting\\\\0006.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(filepath).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im.resize((64, 64))\n",
    "imArr = np.array(im)\n",
    "x = np.expand_dims(imArr, axis=0)\n",
    "x = x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = loaded_model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'painting'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders[res[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testArr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-21c3a3856fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'testArr' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testArr, np.array(testLabels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5226591076249274, 0.8130841127065854]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
